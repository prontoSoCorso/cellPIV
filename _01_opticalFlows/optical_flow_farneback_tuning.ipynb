{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92577245",
   "metadata": {},
   "source": [
    "# Farneback Optical Flow — Tuning & Visualization\n",
    "\n",
    "Questo notebook permette di caricare un video (o una cartella con frames), calcolare l'optical flow con Farneback per diversi set di parametri, visualizzare il flusso sovrapposto (HSV e quiver), e calcolare metriche quantitative di qualità senza ground truth: forward-backward consistency e photometric warp error.\n",
    "\n",
    "**Default input path**: `/home/phd2/Scrivania/CorsoData/OF_prova/D2013.02.19_S0675_I141_1`\n",
    "\n",
    "Esegui le celle in ordine; la cella *Parameters* contiene i parametri da modificare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3ab8cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version: 4.10.0\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Environment & imports\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import json\n",
    "\n",
    "print('OpenCV version:', cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a210d7",
   "metadata": {},
   "source": [
    "## Parameters (modifica qui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "872f8831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT_PATH: /home/phd2/Scrivania/CorsoData/OF_prova/D2013.02.19_S0675_I141_1\n",
      "OUTPUT_DIR: /home/phd2/Scrivania/CorsoData/OF_prova/output_D2013.02.19_S0675_I141_1\n",
      "PARAM_GRID length: 3\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Input: can be a video file or a folder containing sequential frames (png/jpg).\n",
    "DIRNAME = \"D2013.02.19_S0675_I141_1\"\n",
    "BASE_PATH = Path('/home/phd2/Scrivania/CorsoData/OF_prova/')\n",
    "INPUT_PATH = BASE_PATH / DIRNAME\n",
    "# If folder: frames are read sorted lexicographically.\n",
    "\n",
    "# Output\n",
    "OUTPUT_DIR = BASE_PATH / f'output_{DIRNAME}'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Processing options\n",
    "MAX_FRAMES = 200     # None for all\n",
    "FRAME_STEP = 1       # process every FRAME_STEP frames\n",
    "QUIVER_STRIDE = 16   # sampling for quiver overlay\n",
    "SAVE_OVERLAYS = True # Save overlay frames (and optionally make a video)\n",
    "MAKE_VIDEO = True    # Save results as video per parameter set\n",
    "\n",
    "# Parameter grid for Farneback (list of dicts). Add or remove dicts to test.\n",
    "PARAM_GRID = [\n",
    "    {'pyr_scale': 0.5, 'levels': 3, 'winsize': 15, 'iterations': 3, 'poly_n': 5, 'poly_sigma': 1.2, 'flags': 0},\n",
    "    {'pyr_scale': 0.5, 'levels': 5, 'winsize': 21, 'iterations': 5, 'poly_n': 5, 'poly_sigma': 1.1, 'flags': 0},\n",
    "    {'pyr_scale': 0.5, 'levels': 3, 'winsize': 9,  'iterations': 2, 'poly_n': 5, 'poly_sigma': 1.2, 'flags': 0},\n",
    "]\n",
    "\n",
    "# Visual options\n",
    "VIZ_HSV = True\n",
    "VIZ_QUIVER = True\n",
    "QUIVER_COLOR = (0,0,0)  # not used directly for matplotlib quiver\n",
    "\n",
    "# Internal options\n",
    "VERBOSE = True\n",
    "\n",
    "print('INPUT_PATH:', INPUT_PATH)\n",
    "print('OUTPUT_DIR:', OUTPUT_DIR)\n",
    "print('PARAM_GRID length:', len(PARAM_GRID))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da63171",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e58d6c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Utilities for reading frames, computing Farneback flow, conversion to HSV, warping, and metrics\n",
    "\n",
    "def read_frames(input_path: Path, max_frames: int=None, step: int=1, to_gray: bool=True):\n",
    "    \"\"\"Read frames from a video file or a directory. Returns list of frames (uint8, BGR).\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    if input_path.is_file():\n",
    "        cap = cv2.VideoCapture(str(input_path))\n",
    "        idx = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if idx % step == 0:\n",
    "                frames.append(frame)\n",
    "            idx += 1\n",
    "            if max_frames and len(frames) >= max_frames:\n",
    "                break\n",
    "        cap.release()\n",
    "    elif input_path.is_dir():\n",
    "        files = sorted([p for p in input_path.iterdir() if p.suffix.lower() in ('.png','.jpg','.jpeg')])\n",
    "        for i, p in enumerate(files):\n",
    "            if i % step != 0:\n",
    "                continue\n",
    "            frame = cv2.imread(str(p))\n",
    "            if frame is None:\n",
    "                continue\n",
    "            frames.append(frame)\n",
    "            if max_frames and len(frames) >= max_frames:\n",
    "                break\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Input path not found: {input_path}\")\n",
    "\n",
    "    if to_gray:\n",
    "        frames_gray = [cv2.cvtColor(f, cv2.COLOR_BGR2GRAY) for f in frames]\n",
    "        return frames, frames_gray\n",
    "    return frames, None\n",
    "\n",
    "\n",
    "def compute_farneback(prev_gray: np.ndarray, next_gray: np.ndarray, params: Dict[str,Any]):\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, next_gray,\n",
    "                                        None,\n",
    "                                        params['pyr_scale'], params['levels'], params['winsize'],\n",
    "                                        params['iterations'], params['poly_n'], params['poly_sigma'],\n",
    "                                        params.get('flags', 0))\n",
    "    return flow\n",
    "\n",
    "\n",
    "def flow_to_hsv(flow: np.ndarray):\n",
    "    # flow: HxWx2 (float32)\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv = np.zeros((flow.shape[0], flow.shape[1], 3), dtype=np.uint8)\n",
    "    # Hue: angle (0..180), Saturation: 255, Value: normalized magnitude\n",
    "    hsv[...,0] = np.uint8(ang * 180 / np.pi / 2)\n",
    "    hsv[...,1] = 255\n",
    "    v = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    hsv[...,2] = np.uint8(v)\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return bgr, mag, ang\n",
    "\n",
    "\n",
    "def overlay_quiver_bgr(bgr_img: np.ndarray, flow: np.ndarray, stride: int=16, color=(0,0,0)):\n",
    "    # Overlay quiver arrows on BGR image using matplotlib plotting (returns fig)\n",
    "    h, w = bgr_img.shape[:2]\n",
    "    Y, X = np.mgrid[0:h:stride, 0:w:stride]\n",
    "    fx = flow[Y, X, 0]\n",
    "    fy = flow[Y, X, 1]\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    ax.imshow(cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB))\n",
    "    ax.quiver(X, Y, fx, fy, angles='xy', scale_units='xy', scale=1, color='yellow')\n",
    "    ax.set_axis_off()\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def warp_frame(frame_src_gray: np.ndarray, flow_fwd: np.ndarray):\n",
    "    # Warp source frame forward using flow (frame_src at t -> approximate frame at t+1)\n",
    "    h, w = frame_src_gray.shape\n",
    "    flow_x = flow_fwd[...,0].astype(np.float32)\n",
    "    flow_y = flow_fwd[...,1].astype(np.float32)\n",
    "    coords_x, coords_y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    map_x = (coords_x + flow_x).astype(np.float32)\n",
    "    map_y = (coords_y + flow_y).astype(np.float32)\n",
    "    warped = cv2.remap(frame_src_gray, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "    return warped\n",
    "\n",
    "\n",
    "def compute_forward_backward_consistency(flow_fwd: np.ndarray, flow_bwd: np.ndarray):\n",
    "    # Given flow t->t+1 and t+1->t, compute consistency: fwd + warp(bwd, fwd) ~ 0\n",
    "    h, w = flow_fwd.shape[:2]\n",
    "    # warp bwd by fwd\n",
    "    flow_bwd_x = flow_bwd[...,0]\n",
    "    flow_bwd_y = flow_bwd[...,1]\n",
    "    coords_x, coords_y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    map_x = (coords_x + flow_fwd[...,0]).astype(np.float32)\n",
    "    map_y = (coords_y + flow_fwd[...,1]).astype(np.float32)\n",
    "    warped_bwd_x = cv2.remap(flow_bwd_x.astype(np.float32), map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "    warped_bwd_y = cv2.remap(flow_bwd_y.astype(np.float32), map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "    sum_x = flow_fwd[...,0] + warped_bwd_x\n",
    "    sum_y = flow_fwd[...,1] + warped_bwd_y\n",
    "    fb_error = np.sqrt(sum_x**2 + sum_y**2)\n",
    "    return fb_error\n",
    "\n",
    "\n",
    "def photometric_warp_error(frame_t_gray: np.ndarray, frame_t1_gray: np.ndarray, flow_fwd: np.ndarray):\n",
    "    warped = warp_frame(frame_t_gray, flow_fwd)\n",
    "    err = np.abs(warped.astype(np.float32) - frame_t1_gray.astype(np.float32))\n",
    "    return err\n",
    "\n",
    "\n",
    "def summarize_metrics(metrics_list: List[Dict[str,Any]]):\n",
    "    # metrics_list: list of dicts with per-frame metrics. Return aggregated dict.\n",
    "    agg = {}\n",
    "    if not metrics_list:\n",
    "        return agg\n",
    "    # choose numeric keys from first dict\n",
    "    numeric_keys = [k for k,v in metrics_list[0].items() if isinstance(v, (int, float, np.floating, np.integer))]\n",
    "    for k in numeric_keys:\n",
    "        vals = np.array([m[k] for m in metrics_list], dtype=np.float32)\n",
    "        agg[k + '_mean'] = float(np.nanmean(vals))\n",
    "        agg[k + '_std'] = float(np.nanstd(vals))\n",
    "        agg[k + '_median'] = float(np.nanmedian(vals))\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aeccf5",
   "metadata": {},
   "source": [
    "## Processing / Tuning loop\n",
    "\n",
    "La cella seguente esegue la scansione dei parametri in `PARAM_GRID`. Per ogni set calcola metriche medie su tutto il video (o su MAX_FRAMES), salva alcuni overlay e opzionalmente crea un breve video con overlay. Modifica `PARAM_GRID` e le opzioni in alto a piacere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f259be23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing param set 1/3 -> FB_pg0_w15_it3_lv3\n",
      "Saved video: /home/phd2/Scrivania/CorsoData/OF_prova/output_D2013.02.19_S0675_I141_1/FB_pg0_w15_it3_lv3/overlay_FB_pg0_w15_it3_lv3.mp4\n",
      "Saved metrics for FB_pg0_w15_it3_lv3\n",
      "Processing param set 2/3 -> FB_pg1_w21_it5_lv5\n",
      "Saved video: /home/phd2/Scrivania/CorsoData/OF_prova/output_D2013.02.19_S0675_I141_1/FB_pg1_w21_it5_lv5/overlay_FB_pg1_w21_it5_lv5.mp4\n",
      "Saved metrics for FB_pg1_w21_it5_lv5\n",
      "Processing param set 3/3 -> FB_pg2_w9_it2_lv3\n",
      "Saved video: /home/phd2/Scrivania/CorsoData/OF_prova/output_D2013.02.19_S0675_I141_1/FB_pg2_w9_it2_lv3/overlay_FB_pg2_w9_it2_lv3.mp4\n",
      "Saved metrics for FB_pg2_w9_it2_lv3\n",
      "Cell ready. Uncomment the call to process_video_with_paramgrid(...) to run the tuning.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Main processing function (not executed until you run this cell)\n",
    "\n",
    "def process_video_with_paramgrid(input_path: Path, param_grid: List[Dict[str,Any]],\n",
    "                                 max_frames: int=None, frame_step: int=1, quiver_stride: int=16,\n",
    "                                 save_overlays: bool=True, make_video: bool=True, output_base: Path=OUTPUT_DIR):\n",
    "    frames_bgr, frames_gray = read_frames(input_path, max_frames=max_frames, step=frame_step, to_gray=True)\n",
    "    n = len(frames_gray)\n",
    "    if n < 2:\n",
    "        raise RuntimeError('Not enough frames to compute flow')\n",
    "\n",
    "    results = []\n",
    "    for i, params in enumerate(param_grid):\n",
    "        tag = f\"FB_pg{i}_w{params['winsize']}_it{params['iterations']}_lv{params['levels']}\"\n",
    "        out_dir = output_base / tag\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(f'Processing param set {i+1}/{len(param_grid)} ->', tag)\n",
    "\n",
    "        # per-frame metrics\n",
    "        per_frame_metrics = []\n",
    "        overlay_frames = []\n",
    "\n",
    "        prev_flow = None\n",
    "        # We'll compute flows for t->t+1 for t in [0..n-2]\n",
    "        for t in range(n-1):\n",
    "            I0 = frames_gray[t]\n",
    "            I1 = frames_gray[t+1]\n",
    "            flow_fwd = compute_farneback(I0, I1, params)\n",
    "            flow_bwd = compute_farneback(I1, I0, params)\n",
    "\n",
    "            # metrics\n",
    "            fb_err_map = compute_forward_backward_consistency(flow_fwd, flow_bwd)\n",
    "            fb_err = float(np.nanmean(fb_err_map))\n",
    "            photo_err_map = photometric_warp_error(I0, I1, flow_fwd)\n",
    "            photo_err = float(np.nanmean(photo_err_map))\n",
    "            mag = np.sqrt(flow_fwd[...,0]**2 + flow_fwd[...,1]**2)\n",
    "            mag_mean = float(np.nanmean(mag))\n",
    "            mag_std = float(np.nanstd(mag))\n",
    "            temporal_smooth = float(np.nanmean(np.sqrt(((flow_fwd - prev_flow)**2).sum(axis=2)))) if prev_flow is not None else np.nan\n",
    "\n",
    "            per_frame_metrics.append({'frame_idx': t, 'fb_err': fb_err, 'photo_err': photo_err, 'mag_mean': mag_mean, 'mag_std': mag_std, 'temporal_smooth': temporal_smooth})\n",
    "\n",
    "            # visualization: HSV + quiver overlay\n",
    "            vis_hsv_bgr, mag_map, ang_map = flow_to_hsv(flow_fwd)\n",
    "            # overlay HSV onto original (blend)\n",
    "            blended = cv2.addWeighted(frames_bgr[t], 0.7, vis_hsv_bgr, 0.3, 0)\n",
    "\n",
    "            if quiver_stride and quiver_stride > 0:\n",
    "                # create quiver plot and capture as image\n",
    "                fig_q = overlay_quiver_bgr(blended, flow_fwd, stride=quiver_stride)\n",
    "                # save fig to image\n",
    "                fig_q.canvas.draw()\n",
    "                w,h = fig_q.canvas.get_width_height()\n",
    "                img_q = np.frombuffer(fig_q.canvas.buffer_rgba(), dtype='uint8').reshape(h, w, 4)\n",
    "                plt.close(fig_q)\n",
    "                overlay_frames.append(img_q)\n",
    "                if save_overlays:\n",
    "                    cv2.imwrite(str(out_dir / f'overlay_frame_{t:04d}.png'), cv2.cvtColor(img_q, cv2.COLOR_RGB2BGR))\n",
    "            else:\n",
    "                overlay_frames.append(cv2.cvtColor(blended, cv2.COLOR_BGR2RGB))\n",
    "                if save_overlays:\n",
    "                    cv2.imwrite(str(out_dir / f'overlay_frame_{t:04d}.png'), blended)\n",
    "\n",
    "            prev_flow = flow_fwd\n",
    "\n",
    "        # aggregate metrics\n",
    "        agg = summarize_metrics(per_frame_metrics)\n",
    "        stats = {'tag': tag, 'params': params, 'n_frames': n, 'metrics': agg}\n",
    "        results.append(stats)\n",
    "\n",
    "        # make video from overlays\n",
    "        if make_video and overlay_frames:\n",
    "            # use first overlay to get size\n",
    "            h, w = overlay_frames[0].shape[:2]\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            video_path = out_dir / f'overlay_{tag}.mp4'\n",
    "            writer = cv2.VideoWriter(str(video_path), fourcc, 10.0, (w, h))\n",
    "            for img in overlay_frames:\n",
    "                # img is RGB from matplotlib canvas; convert to BGR\n",
    "                bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "                writer.write(bgr)\n",
    "            writer.release()\n",
    "            print('Saved video:', video_path)\n",
    "\n",
    "        # save metrics json\n",
    "        with open(out_dir / 'metrics_summary.json', 'w') as f:\n",
    "            json.dump(stats, f, indent=2)\n",
    "        print('Saved metrics for', tag)\n",
    "\n",
    "    return results\n",
    "\n",
    "# To run: uncomment the line below and execute the cell.\n",
    "results = process_video_with_paramgrid(INPUT_PATH, PARAM_GRID, max_frames=MAX_FRAMES, frame_step=FRAME_STEP, quiver_stride=QUIVER_STRIDE, save_overlays=SAVE_OVERLAYS, make_video=MAKE_VIDEO, output_base=OUTPUT_DIR)\n",
    "\n",
    "print('Cell ready. Uncomment the call to process_video_with_paramgrid(...) to run the tuning.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c9d258",
   "metadata": {},
   "source": [
    "## Quick preview function\n",
    "\n",
    "If vuoi solo vedere il flusso su un singolo frame con un parametro scelto, usa la funzione `preview_one_param(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80f68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Preview helper\n",
    "\n",
    "def preview_one_param(input_path: Path, params: Dict[str,Any], frame_idx: int=0, save_image: bool=False, outdir: Path=OUTPUT_DIR):\n",
    "    frames_bgr, frames_gray = read_frames(input_path, max_frames=frame_idx+2, step=1, to_gray=True)\n",
    "    if len(frames_gray) < frame_idx+2:\n",
    "        raise RuntimeError('Not enough frames for preview')\n",
    "    I0 = frames_gray[frame_idx]\n",
    "    I1 = frames_gray[frame_idx+1]\n",
    "    flow = compute_farneback(I0, I1, params)\n",
    "    vis_hsv_bgr, mag_map, ang_map = flow_to_hsv(flow)\n",
    "    blended = cv2.addWeighted(frames_bgr[frame_idx], 0.7, vis_hsv_bgr, 0.3, 0)\n",
    "    fig = overlay_quiver_bgr(blended, flow, stride=QUIVER_STRIDE)\n",
    "    display(fig)\n",
    "    if save_image:\n",
    "        outdir.mkdir(parents=True, exist_ok=True)\n",
    "        p = outdir / f'preview_frame{frame_idx}_w{params[\"winsize\"]}_it{params[\"iterations\"]}.png'\n",
    "        fig.savefig(p, dpi=150)\n",
    "        print('Saved preview to', p)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Example usage (comment/uncomment as needed):\n",
    "preview_one_param(INPUT_PATH, PARAM_GRID[0], frame_idx=5, save_image=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caa569c",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- Le metriche forward-backward consistency (`fb_err`) e photometric warp error (`photo_err`) non sono ground-truth ma forniscono una misura relativa per confrontare parametri: valori più bassi suggeriscono flussi più coerenti e migliori ricostruzioni.\n",
    "- Il notebook è pensato per esecuzione locale (richiede OpenCV). Se il video è lungo, riduci `MAX_FRAMES` per test rapidi.\n",
    "- Puoi personalizzare `PARAM_GRID` con valori differenti per winsize, iterations, levels ecc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BlastoVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
