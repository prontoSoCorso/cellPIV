{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a5d477f",
   "metadata": {},
   "source": [
    "# Farneback Optical Flow — Ordered frames (preserve original filenames)\n",
    "\n",
    "Questa versione salva gli overlay **con lo stesso nome** dei file di input (prefisso `overlay_` aggiunto solo per chiarezza), senza alcun indice numerico davanti. Esempio: input `D2013.02.19_S0675_I141_1_3_0_0.5h.jpg` -> output `overlay_D2013.02.19_S0675_I141_1_3_0_0.5h.jpg`.\n",
    "\n",
    "Usa questo notebook se preferisci avere gli stessi nomi nei file di output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8afd0e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version: 4.10.0\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Environment & imports\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import json\n",
    "import re\n",
    "\n",
    "print('OpenCV version:', cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c3ccbc",
   "metadata": {},
   "source": [
    "## Parameters (here to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f32384b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT_PATH: /home/phd2/Scrivania/CorsoData/OF_prova/D2013.03.09_S0695_I141_7\n",
      "OUTPUT_DIR: /home/phd2/Scrivania/CorsoData/OF_prova/output_D2013.03.09_S0695_I141_7\n",
      "PARAM_GRID length: 3\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Input: can be a video file or a folder containing sequential frames (png/jpg).\n",
    "DIRNAME = \"D2013.03.09_S0695_I141_7\" # \"D2013.02.19_S0675_I141_1\"\n",
    "BASE_PATH = Path('/home/phd2/Scrivania/CorsoData/OF_prova/')\n",
    "INPUT_PATH = BASE_PATH / DIRNAME\n",
    "# If folder: frames are read sorted lexicographically.\n",
    "\n",
    "# Output\n",
    "OUTPUT_DIR = BASE_PATH / f'output_{DIRNAME}'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Processing options\n",
    "MAX_FRAMES = 200     # None for all\n",
    "FRAME_STEP = 1       # process every FRAME_STEP frames\n",
    "QUIVER_STRIDE = 16   # sampling for quiver overlay\n",
    "SAVE_OVERLAYS = True # Save overlay frames (and optionally make a video)\n",
    "MAKE_VIDEO = True    # Save results as video per parameter set\n",
    "\n",
    "# Parameter grid for Farneback (list of dicts). Add or remove dicts to test.\n",
    "PARAM_GRID = [\n",
    "    # 5) Più veloce / meno smoothing (per confronto): diminuire iterations ma aumentare winsize\n",
    "    {'pyr_scale': 0.5, 'levels': 4, 'winsize': 25, 'iterations': 3, 'poly_n': 5, 'poly_sigma': 1.2, 'flags': 0},    # seems to work ok according to scores\n",
    "\n",
    "    # 6) Usare gaussian window (flag): spesso migliora rumore per immagini con texture finissima\n",
    "    {'pyr_scale': 0.5, 'levels': 5, 'winsize': 21, 'iterations': 5, 'poly_n': 5, 'poly_sigma': 1.2, 'flags': cv2.OPTFLOW_FARNEBACK_GAUSSIAN},   # seems to work ok qualitatively\n",
    "\n",
    "    # 7) mix tra 5 e 6: più veloce ma con gaussian window\n",
    "    {'pyr_scale': 0.5, 'levels': 4, 'winsize': 25, 'iterations': 3, 'poly_n': 5, 'poly_sigma': 1.2, 'flags': cv2.OPTFLOW_FARNEBACK_GAUSSIAN},\n",
    "    ]\n",
    "    \n",
    "\n",
    "\n",
    "# Visual options\n",
    "VIZ_HSV = True\n",
    "VIZ_QUIVER = True\n",
    "QUIVER_COLOR = (0,0,0)\n",
    "\n",
    "# Internal options\n",
    "VERBOSE = True\n",
    "\n",
    "print('INPUT_PATH:', INPUT_PATH)\n",
    "print('OUTPUT_DIR:', OUTPUT_DIR)\n",
    "print('PARAM_GRID length:', len(PARAM_GRID))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fb22e0",
   "metadata": {},
   "source": [
    "## Utilities (natural sort & read frames that also returns filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ac77e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import math\n",
    "\n",
    "def natural_key(s: str):\n",
    "    s = str(s)\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "\n",
    "def read_frames_ordered(input_path: Path, max_frames: int=None, step: int=1, to_gray: bool=True):\n",
    "    frames = []\n",
    "    frame_names = []\n",
    "    if input_path.is_file():\n",
    "        cap = cv2.VideoCapture(str(input_path))\n",
    "        idx = 0\n",
    "        saved_idx = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if idx % step == 0:\n",
    "                frames.append(frame)\n",
    "                frame_names.append(f'frame_{saved_idx:06d}.png')\n",
    "                saved_idx += 1\n",
    "            idx += 1\n",
    "            if max_frames and len(frames) >= max_frames:\n",
    "                break\n",
    "        cap.release()\n",
    "    elif input_path.is_dir():\n",
    "        files = [p for p in input_path.iterdir() if p.suffix.lower() in ('.png','.jpg','.jpeg','.tif','.tiff')]\n",
    "        files_sorted = sorted(files, key=lambda p: natural_key(p.name))\n",
    "        for i, p in enumerate(files_sorted):\n",
    "            if i % step != 0:\n",
    "                continue\n",
    "            frame = cv2.imread(str(p))\n",
    "            if frame is None:\n",
    "                continue\n",
    "            frames.append(frame)\n",
    "            frame_names.append(p.name)  # preserve original filename exactly\n",
    "            if max_frames and len(frames) >= max_frames:\n",
    "                break\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Input path not found: {input_path}\")\n",
    "\n",
    "    if to_gray:\n",
    "        frames_gray = [cv2.cvtColor(f, cv2.COLOR_BGR2GRAY) for f in frames]\n",
    "        return frames, frames_gray, frame_names\n",
    "    return frames, None, frame_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8d9f46",
   "metadata": {},
   "source": [
    "## Flow, viz and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fa6ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def compute_farneback(prev_gray: np.ndarray, next_gray: np.ndarray, params: Dict[str,Any]):\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, next_gray,\n",
    "                                        None,\n",
    "                                        params['pyr_scale'], params['levels'], params['winsize'],\n",
    "                                        params['iterations'], params['poly_n'], params['poly_sigma'],\n",
    "                                        params.get('flags', 0))\n",
    "    return flow\n",
    "\n",
    "\n",
    "def flow_to_hsv(flow: np.ndarray):\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv = np.zeros((flow.shape[0], flow.shape[1], 3), dtype=np.uint8)\n",
    "    hsv[...,0] = np.uint8(ang * 180 / np.pi / 2)\n",
    "    hsv[...,1] = 255\n",
    "    v = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    hsv[...,2] = np.uint8(v)\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return bgr, mag, ang\n",
    "\n",
    "\n",
    "def overlay_quiver_bgr(bgr_img: np.ndarray, flow: np.ndarray, stride: int=16, color=(0,0,0)):\n",
    "    h, w = bgr_img.shape[:2]\n",
    "    Y, X = np.mgrid[0:h:stride, 0:w:stride]\n",
    "    fx = flow[Y, X, 0]\n",
    "    fy = flow[Y, X, 1]\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    ax.imshow(cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB))\n",
    "    ax.quiver(X, Y, fx, fy, angles='xy', scale_units='xy', scale=1, color='yellow')\n",
    "    ax.set_axis_off()\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def warp_frame(frame_src_gray: np.ndarray, flow_fwd: np.ndarray):\n",
    "    h, w = frame_src_gray.shape\n",
    "    flow_x = flow_fwd[...,0].astype(np.float32)\n",
    "    flow_y = flow_fwd[...,1].astype(np.float32)\n",
    "    coords_x, coords_y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    map_x = (coords_x + flow_x).astype(np.float32)\n",
    "    map_y = (coords_y + flow_y).astype(np.float32)\n",
    "    warped = cv2.remap(frame_src_gray, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "    return warped\n",
    "\n",
    "\n",
    "def compute_forward_backward_consistency(flow_fwd: np.ndarray, flow_bwd: np.ndarray):\n",
    "    h, w = flow_fwd.shape[:2]\n",
    "    flow_bwd_x = flow_bwd[...,0]\n",
    "    flow_bwd_y = flow_bwd[...,1]\n",
    "    coords_x, coords_y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    map_x = (coords_x + flow_fwd[...,0]).astype(np.float32)\n",
    "    map_y = (coords_y + flow_fwd[...,1]).astype(np.float32)\n",
    "    warped_bwd_x = cv2.remap(flow_bwd_x.astype(np.float32), map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "    warped_bwd_y = cv2.remap(flow_bwd_y.astype(np.float32), map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "    sum_x = flow_fwd[...,0] + warped_bwd_x\n",
    "    sum_y = flow_fwd[...,1] + warped_bwd_y\n",
    "    fb_error = np.sqrt(sum_x**2 + sum_y**2)\n",
    "    return fb_error\n",
    "\n",
    "\n",
    "def photometric_warp_error(frame_t_gray: np.ndarray, frame_t1_gray: np.ndarray, flow_fwd: np.ndarray):\n",
    "    warped = warp_frame(frame_t_gray, flow_fwd)\n",
    "    err = np.abs(warped.astype(np.float32) - frame_t1_gray.astype(np.float32))\n",
    "    return err\n",
    "\n",
    "\n",
    "def summarize_metrics(metrics_list: List[Dict[str,Any]]):\n",
    "    agg = {}\n",
    "    if not metrics_list:\n",
    "        return agg\n",
    "    numeric_keys = [k for k,v in metrics_list[0].items() if isinstance(v, (int, float, np.floating, np.integer))]\n",
    "    for k in numeric_keys:\n",
    "        vals = np.array([m[k] for m in metrics_list], dtype=np.float32)\n",
    "        agg[k + '_mean'] = float(np.nanmean(vals))\n",
    "        agg[k + '_std'] = float(np.nanstd(vals))\n",
    "        agg[k + '_median'] = float(np.nanmedian(vals))\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed0a5b6",
   "metadata": {},
   "source": [
    "## Processing loop (save overlays using original filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7bacea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing param set 1/3 -> FB_pg0_w25_it3_lv4\n",
      "Saved video: /home/phd2/Scrivania/CorsoData/OF_prova/output_D2013.03.09_S0695_I141_7/FB_pg0_w25_it3_lv4/overlay_FB_pg0_w25_it3_lv4.mp4\n",
      "Saved metrics for FB_pg0_w25_it3_lv4\n",
      "Processing param set 2/3 -> FB_pg1_w21_it5_lv5\n",
      "Saved video: /home/phd2/Scrivania/CorsoData/OF_prova/output_D2013.03.09_S0695_I141_7/FB_pg1_w21_it5_lv5/overlay_FB_pg1_w21_it5_lv5.mp4\n",
      "Saved metrics for FB_pg1_w21_it5_lv5\n",
      "Processing param set 3/3 -> FB_pg2_w25_it3_lv4\n",
      "Saved video: /home/phd2/Scrivania/CorsoData/OF_prova/output_D2013.03.09_S0695_I141_7/FB_pg2_w25_it3_lv4/overlay_FB_pg2_w25_it3_lv4.mp4\n",
      "Saved metrics for FB_pg2_w25_it3_lv4\n",
      "Cell ready. Overlays will be saved using original filenames (prefixed with overlay_).\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "def process_video_preserve_filenames(input_path: Path, param_grid: List[Dict[str,Any]],\n",
    "                                 max_frames: int=None, frame_step: int=1, quiver_stride: int=16,\n",
    "                                 save_overlays: bool=True, make_video: bool=True, output_base: Path=OUTPUT_DIR):\n",
    "    frames_bgr, frames_gray, frame_names = read_frames_ordered(input_path, max_frames=max_frames, step=frame_step, to_gray=True)\n",
    "    n = len(frames_gray)\n",
    "    if n < 2:\n",
    "        raise RuntimeError('Not enough frames to compute flow')\n",
    "\n",
    "    results = []\n",
    "    for i, params in enumerate(param_grid):\n",
    "        tag = f\"FB_pg{i}_w{params['winsize']}_it{params['iterations']}_lv{params['levels']}\"\n",
    "        out_dir = output_base / tag\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(f'Processing param set {i+1}/{len(param_grid)} ->', tag)\n",
    "\n",
    "        per_frame_metrics = []\n",
    "        overlay_frames = []\n",
    "\n",
    "        prev_flow = None\n",
    "        for t in range(n-1):\n",
    "            I0 = frames_gray[t]\n",
    "            I1 = frames_gray[t+1]\n",
    "            flow_fwd = compute_farneback(I0, I1, params)\n",
    "            flow_bwd = compute_farneback(I1, I0, params)\n",
    "\n",
    "            fb_err_map = compute_forward_backward_consistency(flow_fwd, flow_bwd)\n",
    "            fb_err = float(np.nanmean(fb_err_map))\n",
    "            photo_err_map = photometric_warp_error(I0, I1, flow_fwd)\n",
    "            photo_err = float(np.nanmean(photo_err_map))\n",
    "            mag = np.sqrt(flow_fwd[...,0]**2 + flow_fwd[...,1]**2)\n",
    "            mag_mean = float(np.nanmean(mag))\n",
    "            mag_std = float(np.nanstd(mag))\n",
    "            temporal_smooth = float(np.nanmean(np.sqrt(((flow_fwd - prev_flow)**2).sum(axis=2)))) if prev_flow is not None else np.nan\n",
    "\n",
    "            per_frame_metrics.append({'frame_idx': t, 'fb_err': fb_err, 'photo_err': photo_err, 'mag_mean': mag_mean, 'mag_std': mag_std, 'temporal_smooth': temporal_smooth})\n",
    "\n",
    "            # visualization\n",
    "            vis_hsv_bgr, mag_map, ang_map = flow_to_hsv(flow_fwd)\n",
    "            blended = cv2.addWeighted(frames_bgr[t], 0.7, vis_hsv_bgr, 0.3, 0)\n",
    "\n",
    "            if quiver_stride and quiver_stride > 0:\n",
    "                fig_q = overlay_quiver_bgr(blended, flow_fwd, stride=quiver_stride)\n",
    "                fig_q.canvas.draw()\n",
    "                w,h = fig_q.canvas.get_width_height()\n",
    "                img_q = np.frombuffer(fig_q.canvas.buffer_rgba(), dtype='uint8').reshape(h, w, 4)\n",
    "                plt.close(fig_q)\n",
    "                overlay_frames.append(img_q)\n",
    "                if save_overlays:\n",
    "                    # use original filename exactly (no prefix)\n",
    "                    name = frame_names[t]\n",
    "                    out_name = f'overlay_{name}'\n",
    "                    cv2.imwrite(str(out_dir / out_name), cv2.cvtColor(img_q, cv2.COLOR_RGB2BGR))\n",
    "            else:\n",
    "                overlay_frames.append(cv2.cvtColor(blended, cv2.COLOR_BGR2RGB))\n",
    "                if save_overlays:\n",
    "                    name = frame_names[t]\n",
    "                    out_name = f'overlay_{name}'\n",
    "                    cv2.imwrite(str(out_dir / out_name), blended)\n",
    "\n",
    "            prev_flow = flow_fwd\n",
    "\n",
    "        agg = summarize_metrics(per_frame_metrics)\n",
    "        stats = {'tag': tag, 'params': params, 'n_frames': n, 'metrics': agg}\n",
    "        results.append(stats)\n",
    "\n",
    "        # make video\n",
    "        if make_video and overlay_frames:\n",
    "            h, w = overlay_frames[0].shape[:2]\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            video_path = out_dir / f'overlay_{tag}.mp4'\n",
    "            writer = cv2.VideoWriter(str(video_path), fourcc, 10.0, (w, h))\n",
    "            for img in overlay_frames:\n",
    "                bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "                writer.write(bgr)\n",
    "            writer.release()\n",
    "            print('Saved video:', video_path)\n",
    "\n",
    "        with open(out_dir / 'metrics_summary.json', 'w') as f:\n",
    "            json.dump(stats, f, indent=2)\n",
    "        print('Saved metrics for', tag)\n",
    "\n",
    "    return results\n",
    "\n",
    "# To run: uncomment and execute\n",
    "results = process_video_preserve_filenames(INPUT_PATH, PARAM_GRID, max_frames=MAX_FRAMES, frame_step=FRAME_STEP, quiver_stride=QUIVER_STRIDE, save_overlays=SAVE_OVERLAYS, make_video=MAKE_VIDEO, output_base=OUTPUT_DIR)\n",
    "\n",
    "print('Cell ready. Overlays will be saved using original filenames (prefixed with overlay_).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa43fc71",
   "metadata": {},
   "source": [
    "## Quick preview (preserve filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "901878ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def preview_one_param_preserve(input_path: Path, params: Dict[str,Any], frame_idx: int=0, save_image: bool=False, outdir: Path=OUTPUT_DIR):\n",
    "    frames_bgr, frames_gray, frame_names = read_frames_ordered(input_path, max_frames=frame_idx+2, step=1, to_gray=True)\n",
    "    if len(frames_gray) < frame_idx+2:\n",
    "        raise RuntimeError('Not enough frames for preview')\n",
    "    I0 = frames_gray[frame_idx]\n",
    "    I1 = frames_gray[frame_idx+1]\n",
    "    flow = compute_farneback(I0, I1, params)\n",
    "    vis_hsv_bgr, mag_map, ang_map = flow_to_hsv(flow)\n",
    "    blended = cv2.addWeighted(frames_bgr[frame_idx], 0.7, vis_hsv_bgr, 0.3, 0)\n",
    "    fig = overlay_quiver_bgr(blended, flow, stride=QUIVER_STRIDE)\n",
    "    display(fig)\n",
    "    if save_image:\n",
    "        outdir.mkdir(parents=True, exist_ok=True)\n",
    "        p = outdir / f'overlay_{frame_names[frame_idx]}'\n",
    "        fig.savefig(p, dpi=150)\n",
    "        print('Saved preview to', p)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Example usage:\n",
    "# preview_one_param_preserve(INPUT_PATH, PARAM_GRID[0], frame_idx=5, save_image=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f551ae1",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- Questo notebook mantiene esattamente i nomi dei file di input (solo con il prefisso `overlay_` per distinguerli). Se preferisci rimuovere anche il prefisso `overlay_`, dimmi e lo tolgo.\n",
    "- Se processi una cartella con nomi complessi come `D2013.02.19_S0675_I141_1_3_0_0.5h.jpg`, i file di output saranno `overlay_D2013.02.19_S0675_I141_1_3_0_0.5h.jpg`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BlastoVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
