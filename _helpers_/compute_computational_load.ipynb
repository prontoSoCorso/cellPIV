{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "569b1e53",
   "metadata": {},
   "source": [
    "## FLOPS calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b35ef31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported project modules.\n",
      "\n",
      "Model                | Params (M)   | FLOPs (G)    | Time (ms)   \n",
      "-----------------------------------------------------------------\n",
      "LSTMFCN_24h          | 0.9850       | 0.054563     | 10.4716\n",
      "ConvTran_24h         | 0.1892       | 0.013861     | 1.0281\n",
      "ROCKET_24h           | N/A          | N/A          | 4.3663\n",
      "------------------------------------------------------------\n",
      "LSTMFCN_72h          | 0.9850       | 0.177345     | 11.4418\n",
      "ConvTran_72h         | 0.1923       | 0.055739     | 2.6235\n",
      "ROCKET_72h           | N/A          | N/A          | 9.7241\n",
      "------------------------------------------------------------\n",
      "LSTMFCN_120h         | 0.9850       | 0.319001     | 17.7284\n",
      "ConvTran_120h        | 0.1953       | 0.116490     | 5.4947\n",
      "ROCKET_120h          | N/A          | N/A          | 15.0445\n",
      "------------------------------------------------------------\n",
      "Results saved to /home/phd2/Scrivania/CorsoRepo/cellPIV/paper_figures/results_computational_load.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "import logging\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "\n",
    "# Suppress fvcore warnings to keep output clean\n",
    "logging.getLogger(\"fvcore\").setLevel(logging.ERROR)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. SETUP PATHS\n",
    "# -----------------------------------------------------------------------------\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = current_dir\n",
    "while os.path.basename(parent_dir) != \"cellPIV\" and parent_dir != \"/\":\n",
    "    parent_dir = os.path.dirname(parent_dir)\n",
    "\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "    print(f\"Added to sys.path: {parent_dir}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. IMPORT PROJECT MODULES\n",
    "# -----------------------------------------------------------------------------\n",
    "try:\n",
    "    from config import Config_03_train as conf_train\n",
    "    from _03_train._b_LSTMFCN import TimeSeriesClassifier\n",
    "    from _99_ConvTranModel.model import model_factory\n",
    "    import _utils_._utils as utils\n",
    "    \n",
    "    # ROCKET Import\n",
    "    try:\n",
    "        from tsai.models.Rocket import Rocket\n",
    "    except ImportError:\n",
    "        try:\n",
    "            from sktime.transformations.panel.rocket import Rocket\n",
    "        except ImportError:\n",
    "            Rocket = None\n",
    "            \n",
    "    print(\"Successfully imported project modules.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. METRICS HELPERS\n",
    "# -----------------------------------------------------------------------------\n",
    "def get_sequence_length(hours):\n",
    "    # Based on config.py: framePerHour = 4\n",
    "    return int(hours * 4)\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Returns count of trainable parameters in Millions (M)\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6\n",
    "\n",
    "def measure_inference_time(model, dummy_input, device=\"cpu\", repetitions=100):\n",
    "    \"\"\"Measures average inference time in milliseconds (ms)\"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    dummy_input = dummy_input.to(device)\n",
    "\n",
    "    # Warmup\n",
    "    with torch.no_grad():\n",
    "        for _ in range(10): _ = model(dummy_input)\n",
    "    \n",
    "    # Measure\n",
    "    if device == \"cuda\": torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(repetitions): _ = model(dummy_input)\n",
    "    if device == \"cuda\": torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    \n",
    "    return ((end - start) / repetitions) * 1000\n",
    "\n",
    "def measure_rocket_time(input_shape, repetitions=50):\n",
    "    \"\"\"Simulates ROCKET inference time (Transform + Linear)\"\"\"\n",
    "    if Rocket is None: return \"N/A\"\n",
    "    try:\n",
    "        # 1. Prepare Input as NUMPY (ROCKET usually requires CPU Numpy)\n",
    "        # input_shape is (1, 1, T)\n",
    "        X_np = np.random.randn(*input_shape).astype(np.float32)\n",
    "        \n",
    "        # 2. Init ROCKET\n",
    "        # tsai Rocket usually takes (c_in, seq_len)\n",
    "        try:\n",
    "            rocket = Rocket(c_in=input_shape[1], seq_len=input_shape[2])\n",
    "        except:\n",
    "            rocket = Rocket() # sktime fallback\n",
    "            \n",
    "        # 3. Fit (required once)\n",
    "        # Pass numpy array to fit\n",
    "        if hasattr(rocket, 'fit'): \n",
    "            rocket.fit(X_np)\n",
    "            \n",
    "        # 4. Measure Transform Time\n",
    "        start = time.time()\n",
    "        for _ in range(repetitions):\n",
    "            # Transform\n",
    "            if hasattr(rocket, 'transform'):\n",
    "                feats = rocket.transform(X_np)\n",
    "            else:\n",
    "                feats = rocket(X_np) # callable\n",
    "            \n",
    "            # Linear Classifier Simulation (Dot product)\n",
    "            # feats might be a tensor or numpy array depending on library\n",
    "            if isinstance(feats, torch.Tensor):\n",
    "                feats = feats.detach().cpu().numpy()\n",
    "            \n",
    "            # Simulate linear layer: features @ weights\n",
    "            # feats shape: (Batch, N_Kernels)\n",
    "            _ = feats @ np.random.randn(feats.shape[1], 1)\n",
    "            \n",
    "        end = time.time()\n",
    "        return ((end - start) / repetitions) * 1000\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Err: {str(e)[:20]}\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. MAIN LOOP\n",
    "# -----------------------------------------------------------------------------\n",
    "day_map = {1: 24, 3: 72, 5: 120}\n",
    "device = \"cpu\" # CPU for fair comparison\n",
    "\n",
    "results_log = []\n",
    "output_file = os.path.join(parent_dir, \"paper_figures\", \"results_computational_load.txt\")\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "header = f\"{'Model':<20} | {'Params (M)':<12} | {'FLOPs (G)':<12} | {'Time (ms)':<12}\"\n",
    "print(f\"\\n{header}\")\n",
    "print(\"-\" * len(header))\n",
    "results_log.append(header)\n",
    "\n",
    "base_models_path = conf_train.output_model_base_dir\n",
    "\n",
    "for day in [1, 3, 5]:\n",
    "    hours = day_map[day]\n",
    "    T = get_sequence_length(hours)\n",
    "    # Input shape: (Batch=1, Channels=1, Time)\n",
    "    input_shape = (1, 1, T)\n",
    "    dummy_input = torch.randn(*input_shape)\n",
    "\n",
    "    # --- 1. LSTMFCN ---\n",
    "    try:\n",
    "        model = TimeSeriesClassifier(input_channels=1, num_classes=2)\n",
    "        params = count_parameters(model)\n",
    "        \n",
    "        # Calculate FLOPs (suppressing warnings)\n",
    "        flops = FlopCountAnalysis(model, dummy_input)\n",
    "        flops.unsupported_ops_warnings(False) # Clean output\n",
    "        flops_g = flops.total() / 1e9\n",
    "        \n",
    "        time_ms = measure_inference_time(model, dummy_input, device=device)\n",
    "        \n",
    "        msg = f\"LSTMFCN_{hours}h\".ljust(20) + f\" | {params:.4f}\".ljust(15) + f\" | {flops_g:.6f}\".ljust(15) + f\" | {time_ms:.4f}\"\n",
    "        print(msg)\n",
    "        results_log.append(msg)\n",
    "    except Exception as e:\n",
    "        err = f\"LSTMFCN_{hours}h: {str(e)}\"\n",
    "        print(err)\n",
    "        results_log.append(err)\n",
    "\n",
    "    # --- 2. ConvTran ---\n",
    "    try:\n",
    "        conf_local = copy.deepcopy(conf_train)\n",
    "        conf_local.Data_shape = (1, T)\n",
    "        if not hasattr(conf_local, 'num_labels'): conf_local.num_labels = 2\n",
    "        \n",
    "        model = model_factory(conf_local)\n",
    "        params = count_parameters(model)\n",
    "        \n",
    "        flops = FlopCountAnalysis(model, dummy_input)\n",
    "        flops.unsupported_ops_warnings(False)\n",
    "        flops_g = flops.total() / 1e9\n",
    "        \n",
    "        time_ms = measure_inference_time(model, dummy_input, device=device)\n",
    "        \n",
    "        msg = f\"ConvTran_{hours}h\".ljust(20) + f\" | {params:.4f}\".ljust(15) + f\" | {flops_g:.6f}\".ljust(15) + f\" | {time_ms:.4f}\"\n",
    "        print(msg)\n",
    "        results_log.append(msg)\n",
    "    except Exception as e:\n",
    "        err = f\"ConvTran_{hours}h: {str(e)}\"\n",
    "        print(err)\n",
    "        results_log.append(err)\n",
    "\n",
    "    # --- 3. ROCKET ---\n",
    "    try:\n",
    "        time_ms = measure_rocket_time(input_shape)\n",
    "        if isinstance(time_ms, float):\n",
    "            t_str = f\"{time_ms:.4f}\"\n",
    "        else:\n",
    "            t_str = time_ms\n",
    "            \n",
    "        msg = f\"ROCKET_{hours}h\".ljust(20) + f\" | {'N/A':<12} | {'N/A':<12} | {t_str}\"\n",
    "        print(msg)\n",
    "        results_log.append(msg)\n",
    "    except Exception as e:\n",
    "        err = f\"ROCKET_{hours}h: {str(e)}\"\n",
    "        print(err)\n",
    "        results_log.append(err)\n",
    "        \n",
    "    print(\"-\" * 60)\n",
    "    results_log.append(\"-\" * 60)\n",
    "\n",
    "# Save\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(\"\\n\".join(results_log))\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BlastoVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
