{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd18830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def get_positional_encoding(seq_len: int, d_model: int, device=None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Sinusoidal positional encoding (Vaswani et al.).\n",
    "    Returns a tensor shape [seq_len, d_model].\n",
    "    \"\"\"\n",
    "    pe = torch.zeros(seq_len, d_model, device=device)\n",
    "    position = torch.arange(0, seq_len, dtype=torch.float, device=device).unsqueeze(1)  # [L,1]\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float, device=device) * (-math.log(10000.0) / d_model))\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    if d_model % 2 == 1:\n",
    "        # odd-d_model: handle the last column safely\n",
    "        pe[:, 1::2] = torch.cos(position * div_term[:-1])\n",
    "    else:\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    return pe  # [L, d_model]\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Lightweight attention mechanism for feature fusion\"\"\"\n",
    "    def __init__(self, d_model, n_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.orig_d = d_model\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        # compute padded dimension (ceiling to nearest multiple of n_heads)\n",
    "        pad_to = math.ceil(d_model / n_heads) * n_heads\n",
    "        self.pad_extra = pad_to - d_model\n",
    "\n",
    "        # project up if padding needed, else identity\n",
    "        self.pre_proj = nn.Linear(d_model, pad_to) if pad_to != d_model else nn.Identity()\n",
    "        self.d_model = pad_to\n",
    "        self.d_k = pad_to // n_heads\n",
    "\n",
    "        # attention projections\n",
    "        self.w_q = nn.Linear(pad_to, pad_to, bias=False)\n",
    "        self.w_k = nn.Linear(pad_to, pad_to, bias=False)\n",
    "        self.w_v = nn.Linear(pad_to, pad_to, bias=False)\n",
    "        self.w_o = nn.Linear(pad_to, pad_to)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [B, L, orig_d]\n",
    "        returns: [B, L, orig_d]\n",
    "        \"\"\"\n",
    "        x = self.pre_proj(x)  # [B, L, pad_to]\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        # project and reshape for multi-head\n",
    "        Q = self.w_q(x).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.w_k(x).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.w_v(x).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        attn_weights = torch.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context = torch.matmul(attn_weights, V)  # [B, heads, L, d_k]\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)  # [B, L, pad_to]\n",
    "\n",
    "        out = self.w_o(context)  # [B, L, pad_to]\n",
    "\n",
    "        # slice off padding if added\n",
    "        if self.pad_extra:\n",
    "            out = out[..., : self.orig_d]\n",
    "\n",
    "        return out  # [B, L, orig_d]\n",
    "\n",
    "\n",
    "class ResidualConvBlock(nn.Module):\n",
    "    \"\"\"Conv1D with residual + squeeze-excitation + batchnorm \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, kernel, dropout, se_ratio=0.25):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_ch, out_ch, kernel, padding=kernel // 2)\n",
    "        self.conv2 = nn.Conv1d(out_ch, out_ch, kernel, padding=kernel // 2)\n",
    "        self.norm1 = nn.BatchNorm1d(out_ch)\n",
    "        self.norm2 = nn.BatchNorm1d(out_ch)\n",
    "        self.act = nn.GELU()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "        # Squeeze-and-Excitation\n",
    "        se_ch = max(1, int(out_ch * se_ratio))\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Conv1d(out_ch, se_ch, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(se_ch, out_ch, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Residual connection (project if channels differ)\n",
    "        self.res = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "        self.res_norm = nn.BatchNorm1d(out_ch) if in_ch != out_ch else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, C, L]\n",
    "        residual = self.res(x)\n",
    "        if hasattr(self.res_norm, \"weight\"):\n",
    "            residual = self.res_norm(residual)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.drop(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out)\n",
    "\n",
    "        se_weight = self.se(out)  # [B, C_out, 1]\n",
    "        out = out * se_weight\n",
    "\n",
    "        out = self.act(out + residual)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ModalitySpecificEncoder(nn.Module):\n",
    "    \"\"\"Encoder for the EEG channels per timestep\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, L, input_dim]\n",
    "        return self.encoder(x)  # [B, L, hidden_dim]\n",
    "\n",
    "\n",
    "class EEGRegressor(nn.Module):\n",
    "    \"\"\"\n",
    "    Single-task EEG regressor that accepts EEG with 129 channels and sequence length 200.\n",
    "    Returns a single scalar per sample (regression).\n",
    "\n",
    "    Default hyperparameters are provided but can be overridden.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        eeg_channels: int = 129,\n",
    "        enc_hidden_dim: int = 64,\n",
    "        dropout_enc: float = 0.1,\n",
    "        num_features: int = 128,\n",
    "        n_heads: int = 4,\n",
    "        dropout_attn: float = 0.1,\n",
    "        lstm_hidden_dim: int = 64,\n",
    "        lstm_layers: int = 2,\n",
    "        bidirectional: bool = True,\n",
    "        dropout_lstm: float = 0.2,\n",
    "        cnn_filter_sizes: list = (64, 128, 256),\n",
    "        cnn_kernel_sizes: list = (3, 3, 3),\n",
    "        dropout_cnn: float = 0.2,\n",
    "        se_ratio: float = 0.25,\n",
    "        dropout_classifier: float = 0.3,\n",
    "        use_positional: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Positional Encoding flag\n",
    "        self.use_positional = use_positional\n",
    "\n",
    "        # --- Encoder for EEG (per-timestep channel encoding) ---\n",
    "        self.encoder = ModalitySpecificEncoder(eeg_channels, enc_hidden_dim, dropout_enc)\n",
    "\n",
    "        # Fusion (only one modality => enc_hidden_dim)\n",
    "        fusion_dim = enc_hidden_dim\n",
    "        self.fusion_proj = nn.Linear(fusion_dim, num_features)\n",
    "        self.fusion_norm = nn.LayerNorm(num_features)\n",
    "\n",
    "        # Attention for temporal modelling\n",
    "        self.attention = MultiHeadAttention(num_features, n_heads=n_heads, dropout=dropout_attn)\n",
    "        # Transformer-style post-attention normalization + dropout\n",
    "        self.attn_dropout = nn.Dropout(dropout_attn)\n",
    "        self.attn_norm = nn.LayerNorm(num_features)\n",
    "\n",
    "        # LSTM branch\n",
    "        lstm_input_size = num_features\n",
    "        self.lstm = nn.LSTM(\n",
    "            lstm_input_size,\n",
    "            lstm_hidden_dim,\n",
    "            num_layers=lstm_layers,\n",
    "            dropout=dropout_lstm if lstm_layers > 1 else 0.0,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        lstm_out_dim = lstm_hidden_dim * (2 if bidirectional else 1)\n",
    "\n",
    "        # CNN branch (Conv1d expects channels-first: [B, C, L])\n",
    "        assert len(cnn_filter_sizes) == 3 and len(cnn_kernel_sizes) == 3, \"Need 3 filter sizes and 3 kernel sizes\"\n",
    "        fs = list(cnn_filter_sizes)\n",
    "        ks = list(cnn_kernel_sizes)\n",
    "        self.conv_blocks = nn.ModuleList([\n",
    "            ResidualConvBlock(num_features, fs[0], ks[0], dropout_cnn, se_ratio),\n",
    "            ResidualConvBlock(fs[0], fs[1], ks[1], dropout_cnn, se_ratio),\n",
    "            ResidualConvBlock(fs[1], fs[2], ks[2], dropout_cnn, se_ratio),\n",
    "        ])\n",
    "\n",
    "        # Pooling\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.global_max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        # Classifier (regression head)\n",
    "        conv_feat_dim = fs[-1] * 2\n",
    "        final_dim = lstm_out_dim + conv_feat_dim\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_classifier),\n",
    "            nn.Linear(final_dim, max(16, final_dim // 2)),\n",
    "            nn.LayerNorm(max(16, final_dim // 2)),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_classifier * 0.5),\n",
    "            nn.Linear(max(16, final_dim // 2), 1),  # scalar regressor\n",
    "        )\n",
    "\n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Conv1d):\n",
    "            torch.nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, (nn.BatchNorm1d, nn.LayerNorm)):\n",
    "            if hasattr(module, \"weight\"):\n",
    "                torch.nn.init.ones_(module.weight)\n",
    "            if hasattr(module, \"bias\"):\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [B, L, 129]  (channels last per timestep)\n",
    "        returns: [B]    (scalar regression per sample)\n",
    "        \"\"\"\n",
    "        B, L, C = x.shape\n",
    "        # encode per-timestep channels\n",
    "        enc = self.encoder(x)  # [B, L, enc_hidden_dim]\n",
    "\n",
    "        # fusion proj (single modality)\n",
    "        fused = self.fusion_proj(enc)  # [B, L, num_features]\n",
    "        fused = self.fusion_norm(fused)\n",
    "\n",
    "        # positional encoding (sinusoidal)\n",
    "        if self.use_positional:\n",
    "            pos = get_positional_encoding(L, fused.size(-1), device=fused.device)  # [L, D]\n",
    "            fused = fused + pos.unsqueeze(0)  # broadcast over batch\n",
    "\n",
    "        # self-attention\n",
    "        attn_out = self.attention(fused)\n",
    "        attn_out = self.attn_dropout(attn_out)\n",
    "        fused = self.attn_norm(fused + attn_out)  # residual\n",
    "\n",
    "        # LSTM branch\n",
    "        lstm_out, (h_n, _) = self.lstm(fused)  # lstm_out: [B, L, hidden*dirs]\n",
    "        if self.lstm.bidirectional:\n",
    "            h_forward = h_n[-2]\n",
    "            h_backward = h_n[-1]\n",
    "            h_final = torch.cat([h_forward, h_backward], dim=1)  # [B, lstm_hidden*2]\n",
    "        else:\n",
    "            h_final = h_n[-1]  # [B, lstm_hidden]\n",
    "\n",
    "        # CNN branch\n",
    "        x_conv = fused.permute(0, 2, 1)  # [B, num_features, L]\n",
    "        for block in self.conv_blocks:\n",
    "            x_conv = block(x_conv)  # [B, ch, L]\n",
    "\n",
    "        conv_avg = self.global_avg_pool(x_conv).squeeze(-1)  # [B, fs[-1]]\n",
    "        conv_max = self.global_max_pool(x_conv).squeeze(-1)  # [B, fs[-1]]\n",
    "        conv_feat = torch.cat([conv_avg, conv_max], dim=1)  # [B, fs[-1]*2]\n",
    "\n",
    "        # final concatenation + regression head\n",
    "        final_feat = torch.cat([h_final, conv_feat], dim=1)  # [B, final_dim]\n",
    "        out = self.classifier(final_feat).squeeze(-1)  # [B]\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4207d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "L = 200   # time length\n",
    "C = 129   # channels\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = EEGRegressor(\n",
    "        eeg_channels=C,\n",
    "        enc_hidden_dim=64,\n",
    "        num_features=128,\n",
    "        n_heads=4,\n",
    "        lstm_hidden_dim=64,\n",
    "        lstm_layers=2,\n",
    "        bidirectional=True,\n",
    "        cnn_filter_sizes=(64, 128, 256),\n",
    "        cnn_kernel_sizes=(3, 3, 3),\n",
    "    ).to(device)\n",
    "\n",
    "# Specify optimizer and criterion\n",
    "optimizer = optim.Adamax(params=model.parameters(), lr=1e-3)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "print(\"Number of total parameters: \", sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c32df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch Dataloader\n",
    "batch_size = 32\n",
    "num_workers = 1 if device.type == \"cpu\" else 2\n",
    "pin_memory = True if device.type == \"cuda\" else False\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# optional: for notebook live update\n",
    "try:\n",
    "    from IPython.display import clear_output\n",
    "    _have_ipy = True\n",
    "except Exception:\n",
    "    _have_ipy = False\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    windows_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    windows_ds_val,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "\n",
    "def ensure_channels_last(X: torch.Tensor, model) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Ensure X has shape [B, L, C] where C == encoder input dim (usually 129).\n",
    "    If input is [B, C, L], it permutes to [B, L, C].\n",
    "    \"\"\"\n",
    "    if X.dim() != 3:\n",
    "        raise ValueError(f\"Expected X dim==3 (B,L,C). Got {X.dim()} dims: {list(X.shape)}\")\n",
    "    expected_in = model.encoder.encoder[0].in_features  # 129 di default\n",
    "    # case 1: already [B, L, C]\n",
    "    if X.size(-1) == expected_in:\n",
    "        return X\n",
    "    # case 2: [B, C, L] -> permute\n",
    "    if X.size(1) == expected_in:\n",
    "        return X.permute(0, 2, 1).contiguous()\n",
    "    # otherwise print helpful info and raise\n",
    "    raise ValueError(f\"Can't reconcile input shape {list(X.shape)} with model expected channels {expected_in}.\"\n",
    "                     \" If your dataset returns (C,L) per sample, permute to (L,C).\")\n",
    "\n",
    "\n",
    "# Training loop parameters\n",
    "n_epochs = 100\n",
    "grad_clip_max_norm = 5.0  # utile per stabilizzare l'addestramento\n",
    "\n",
    "train_epoch_losses = []\n",
    "val_epoch_losses = []\n",
    "\n",
    "epoch_losses = []   # store avg loss per epoch\n",
    "all_batch_losses = []  # optional: store all batch losses if you want more granular plot\n",
    "\n",
    "# --- Training loop ---\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    batch_count = 0\n",
    "\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # puoi adattare se la struttura del tuo batch è diversa\n",
    "        X, y, *rest = batch   # rest contiene crop_inds, infos o simili\n",
    "\n",
    "        # Move to device & correct dtype\n",
    "        X = X.to(dtype=torch.float32, device=device)\n",
    "        y = y.to(dtype=torch.float32, device=device)\n",
    "\n",
    "        # ensure X shape is [B, L, C]\n",
    "        try:\n",
    "            X = ensure_channels_last(X, model)\n",
    "        except Exception as e:\n",
    "            # utili informazioni di debug: stampa forme e alza l'eccezione\n",
    "            print(\"=== SHAPE DEBUG ===\")\n",
    "            print(\"X.shape:\", list(X.shape))\n",
    "            print(\"model expected channels (encoder input):\", model.encoder.encoder[0].in_features)\n",
    "            raise e\n",
    "\n",
    "        # Normalize target shape -> [B]\n",
    "        if y.dim() > 1 and y.size(-1) == 1:\n",
    "            y = y.view(-1)\n",
    "        else:\n",
    "            # se ha shape [B,1,1,...] o simili\n",
    "            y = y.squeeze()\n",
    "        # ATTENZIONE: se y è (B,), squeeze non cambia nulla\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X)   # modello restituisce [B]\n",
    "\n",
    "        # ensure prediction shape is [B]\n",
    "        if y_pred.dim() > 1 and y_pred.size(-1) == 1:\n",
    "            y_pred = y_pred.view(-1)\n",
    "        else:\n",
    "            y_pred = y_pred.squeeze()\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient clipping (opzionale ma consigliato)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip_max_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        batch_count += 1\n",
    "\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"Epoch {epoch} - step {idx}, loss: {loss.item():.6f}\")\n",
    "\n",
    "    avg_train_loss = running_loss / max(1, batch_count)\n",
    "    train_epoch_losses.append(avg_train_loss)\n",
    "\n",
    "    # ---- validation ----\n",
    "    model.eval()\n",
    "    val_running = 0.0\n",
    "    val_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(dataloader_val):\n",
    "            X, y, *rest = batch\n",
    "            X = X.to(device=device, dtype=torch.float32)\n",
    "            y = y.to(device=device, dtype=torch.float32)\n",
    "\n",
    "            # ensure correct input layout\n",
    "            X = ensure_channels_last(X, model)\n",
    "\n",
    "            # normalize y shape -> [B]\n",
    "            if y.dim() > 1 and y.size(-1) == 1:\n",
    "                y = y.view(-1)\n",
    "            else:\n",
    "                y = y.squeeze()\n",
    "\n",
    "            y_pred = model(X)\n",
    "            if y_pred.dim() > 1 and y_pred.size(-1) == 1:\n",
    "                y_pred = y_pred.view(-1)\n",
    "            else:\n",
    "                y_pred = y_pred.squeeze()\n",
    "\n",
    "            loss_val = criterion(y_pred, y)\n",
    "            val_running += loss_val.item()\n",
    "            val_batches += 1\n",
    "\n",
    "            if idx % 50 == 0:\n",
    "                print(f\"[Val]   Epoch {epoch} - step {idx}, batch loss: {loss_val.item():.6f}\")\n",
    "    \n",
    "    avg_val_loss = val_running / max(1, val_batches)\n",
    "    val_epoch_losses.append(avg_val_loss)\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch} finished. Train avg loss: {avg_train_loss:.6f} | Val avg loss: {avg_val_loss:.6f}\")\n",
    "\n",
    "    # ---- plot train & val losses so far ----\n",
    "    if _have_ipy:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    epochs = range(1, len(train_epoch_losses) + 1)\n",
    "    plt.plot(epochs, train_epoch_losses, marker='o', linestyle='-', label='Train')   # default colors\n",
    "    plt.plot(epochs, val_epoch_losses, marker='o', linestyle='-', label='Validation')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Avg L1 loss\")\n",
    "    plt.title(\"Training and Validation loss per epoch\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Finally, we can save the model for later use\n",
    "torch.save(model.state_dict(), \"model_weights_challenge_2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db9821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# --- dataloader_test (use your provided definition) ---\n",
    "dataloader_test = DataLoader(\n",
    "    windows_ds_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,          # recommended: set to False for deterministic evaluation\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# Ensure model is on device\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "batch_losses = []\n",
    "batch_indices = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, batch in enumerate(dataloader_test):\n",
    "        # Unpack batch\n",
    "        X, y, *rest = batch\n",
    "\n",
    "        # Move to device & float\n",
    "        X = X.to(device=device, dtype=torch.float32)\n",
    "        y = y.to(device=device, dtype=torch.float32)\n",
    "\n",
    "        # Ensure shape [B, L, C]\n",
    "        X = ensure_channels_last(X, model)  # reuse from training script\n",
    "\n",
    "        # Normalize target shape [B]\n",
    "        if y.dim() > 1 and y.size(-1) == 1:\n",
    "            y = y.view(-1)\n",
    "        else:\n",
    "            y = y.squeeze()\n",
    "\n",
    "        # Model forward\n",
    "        y_pred = model(X)\n",
    "        if y_pred.dim() > 1 and y_pred.size(-1) == 1:\n",
    "            y_pred = y_pred.view(-1)\n",
    "        else:\n",
    "            y_pred = y_pred.squeeze()\n",
    "\n",
    "        # Loss\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss_val = loss.item()\n",
    "\n",
    "        batch_losses.append(loss_val)\n",
    "        batch_indices.append(idx)\n",
    "\n",
    "        # print progress (every 10 batches)\n",
    "        if idx % 10 == 0:\n",
    "            print(f\"Test step {idx}, batch loss: {loss_val:.6f}\")\n",
    "\n",
    "# Summary\n",
    "num_batches = len(batch_losses)\n",
    "avg_test_loss = float(sum(batch_losses) / max(1, num_batches))\n",
    "print(f\"Test finished. Num batches: {num_batches}. Avg L1 loss: {avg_test_loss:.6f}\")\n",
    "\n",
    "# Plot batch losses\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(batch_indices, batch_losses, marker='o', linestyle='-')  # single plot, default colors\n",
    "plt.axhline(avg_test_loss, color='k', linewidth=1.0, linestyle='--', label=f\"Avg loss = {avg_test_loss:.4f}\")\n",
    "plt.xlabel(\"Batch index\")\n",
    "plt.ylabel(\"L1 loss\")\n",
    "plt.title(\"Test loss per batch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "out_fig = \"test_loss.png\"\n",
    "plt.savefig(out_fig)\n",
    "print(f\"Saved plot to {out_fig}\")\n",
    "\n",
    "# Optionally save per-batch losses to CSV for further analysis\n",
    "out_csv = \"test_batch_losses.csv\"\n",
    "with open(out_csv, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"batch_idx\", \"loss\"])\n",
    "    for bi, loss_val in zip(batch_indices, batch_losses):\n",
    "        writer.writerow([bi, loss_val])\n",
    "print(f\"Saved batch losses to {out_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
